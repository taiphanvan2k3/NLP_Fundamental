{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5XnO70yfpKW"
      },
      "source": [
        "## Retrieval\n",
        "\n",
        "- Ý tưởng:\n",
        "  + Sử dụng 1 model Word2Vec của Google để biến đổi 1 word thành 1 vector có chiều dài 300\n",
        "  + Với tất cả document trong Dataset thì sẽ áp dụng tiền xử lý rồi dùng model đó để tìm ra vector đại diện cho mỗi câu bằng cách mean của các vector từ\n",
        "  + Với 1 query document thì cũng áp dụng tiền xử lý, dùng model tìm ra vector đại diện -> Xong thì dùng cosine similarity để trả về các câu có độ tương đồng với câu đầu vào đó"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF03PU8cHgn8",
        "outputId": "3ab22915-4590-4abb-c554-d624c8667d15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvnJs0Xaf9Bb",
        "outputId": "0d79e024-663a-42e7-b6e6-a67b90bd0746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1xiv3cJ70E8QNV0XL9gs6EDLjOnszeQ0O/Bai 6 - Code\n"
          ]
        }
      ],
      "source": [
        "# Chuyển đến vị trí thư mục hiện tại\n",
        "%cd /content/drive/MyDrive/Colab/chapter6_solution/Bai 6 - Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzbFOFdQgAL9",
        "outputId": "fc8933ef-4455-492b-b613-beeafde36dc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Chapter 6.ipynb'\t\t      Preprocessing_and_Visualizing.ipynb\n",
            " DL_Model.ipynb\t\t\t      spam.csv\n",
            " dts_20k_preprocessed.csv\t      weights-improvement-01-7.9131.hdf5\n",
            " dts_20k_raw.csv\t\t      weights-improvement-02-7.1496.hdf5\n",
            " GoogleNews-vectors-negative300.bin   weights-improvement-03-7.0137.hdf5\n",
            " model.png\t\t\t      weights-improvement-04-6.9062.hdf5\n",
            " NaiveBayesClassifier.ipynb\t      weights-improvement-05-6.8229.hdf5\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkoxWOsJgNdO",
        "outputId": "600803a8-aea9-404a-8221-78ba04f3efe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy\n",
            "  Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.5\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Collecting scipy\n",
            "  Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (2.2.5)\n",
            "Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.5 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.15.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall numpy\n",
        "!pip install --upgrade scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "6XBKww1cgRa8",
        "outputId": "dcb999d3-c008-4f28-f330-49aea03b8006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 7.1.0\n",
            "    Uninstalling smart-open-7.1.0:\n",
            "      Successfully uninstalled smart-open-7.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.2\n",
            "    Uninstalling scipy-1.15.2:\n",
            "      Successfully uninstalled scipy-1.15.2\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 4.3.3\n",
            "    Uninstalling gensim-4.3.3:\n",
            "      Successfully uninstalled gensim-4.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "0accb45d9037470f8d4a43ca704bc9c1",
              "pip_warning": {
                "packages": [
                  "smart_open",
                  "wrapt"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crMhafUIgex7",
        "outputId": "d79a4da8-3f1f-4cf3-bebd-5e6c2294e5bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import itertools\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import scipy\n",
        "from scipy import spatial\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "import re\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpdEgifvhKmZ",
        "outputId": "73e676c1-2325-4350-d8b7-3d68f92d3077"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mGN9VlpKg1NC"
      },
      "outputs": [],
      "source": [
        "# Randomly taking sentences from internet\n",
        "Doc1 = [\"With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.\" ]\n",
        "\n",
        "Doc2 = [\"Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\"]\n",
        "\n",
        "Doc3 = [\"He points out that public transport is very good in Mumbai and New Delhi, where there is a good network of suburban and metro rail systems.\"]\n",
        "\n",
        "Doc4 = [\"But the man behind the wickets at the other end was watching just as keenly. With an affirmative nod from Dhoni, India captain Rohit Sharma promptly asked for a review. Sure enough, the ball would have clipped the top of middle and leg.\"]\n",
        "\n",
        "# Put all the documents in one list\n",
        "\n",
        "all_sentences = Doc1 + Doc2 + Doc3 + Doc4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg6_Ixf2h0ou"
      },
      "source": [
        "### Thử nghiệm nlkt.word_tokenize và tokenizer.tokenize của TokTokTokenizer\n",
        "\n",
        "- nltk.word_tokenize() thường được coi là mạnh hơn và chính xác hơn trong việc xử lý các trường hợp phức tạp so với ToktokTokenizer(). Lý do là vì:\n",
        "\n",
        "- Mô hình ngữ pháp và quy tắc phức tạp:\n",
        "\n",
        "  + `nltk.word_tokenize()` sử dụng mô hình Punkt Tokenizer (một mô hình phân tích cú pháp) để tự động nhận diện các từ và dấu câu trong văn bản. Điều này giúp nó xử lý các trường hợp phức tạp như:\n",
        "\n",
        "    + Tách từ trong các cụm từ ghép.\n",
        "\n",
        "    + Xử lý dấu câu kề nhau (ví dụ: \"Let's\" sẽ được tách thành \"Let\" và \"'s\").\n",
        "\n",
        "    + Xử lý các ký tự đặc biệt và các từ lạ trong ngữ cảnh.\n",
        "\n",
        "  + Xử lý các trường hợp đặc biệt:\n",
        "\n",
        "    `nltk.word_tokenize()` có thể nhận diện và xử lý các từ hợp nhất (như \"I'm\", \"don't\", \"let's\", v.v.), trong khi ToktokTokenizer có thể gặp khó khăn với các trường hợp này vì nó sử dụng cách tiếp cận đơn giản hơn, chủ yếu dựa vào khoảng trắng và dấu câu.\n",
        "\n",
        "  + Độ chính xác cao hơn:\n",
        "\n",
        "    `nltk.word_tokenize()` có thể phân tách chính xác hơn trong các văn bản có dấu câu phức tạp hoặc các cụm từ có dấu câu đặc biệt. Điều này rất quan trọng khi làm việc với văn bản tự nhiên, nơi các ký tự đặc biệt và cấu trúc câu rất đa dạng."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBsgOqyrgRZ4",
        "outputId": "388f0f49-b8ca-4c56-dd44-455deed3c076"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['With',\n",
              " 'the',\n",
              " 'Union',\n",
              " 'cabinet',\n",
              " 'approving',\n",
              " 'the',\n",
              " 'amendments',\n",
              " 'to',\n",
              " 'the',\n",
              " 'Motor',\n",
              " 'Vehicles',\n",
              " 'Act',\n",
              " ',',\n",
              " '2016',\n",
              " ',',\n",
              " 'those',\n",
              " 'caught',\n",
              " 'for',\n",
              " 'drunken',\n",
              " 'driving',\n",
              " 'will',\n",
              " 'have',\n",
              " 'to',\n",
              " 'have',\n",
              " 'really',\n",
              " 'deep',\n",
              " 'pockets',\n",
              " ',',\n",
              " 'as',\n",
              " 'the',\n",
              " 'fine',\n",
              " 'payable',\n",
              " 'in',\n",
              " 'court',\n",
              " 'has',\n",
              " 'been',\n",
              " 'enhanced',\n",
              " 'to',\n",
              " 'Rs',\n",
              " '10,000',\n",
              " 'for',\n",
              " 'first-time',\n",
              " 'offenders',\n",
              " '.']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.word_tokenize(Doc1[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM8VaDs9hTeZ",
        "outputId": "de8cd5cd-c4fa-4c30-d5d1-9a56ca8206bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['With',\n",
              " 'the',\n",
              " 'Union',\n",
              " 'cabinet',\n",
              " 'approving',\n",
              " 'the',\n",
              " 'amendments',\n",
              " 'to',\n",
              " 'the',\n",
              " 'Motor',\n",
              " 'Vehicles',\n",
              " 'Act',\n",
              " ',',\n",
              " '2016',\n",
              " ',',\n",
              " 'those',\n",
              " 'caught',\n",
              " 'for',\n",
              " 'drunken',\n",
              " 'driving',\n",
              " 'will',\n",
              " 'have',\n",
              " 'to',\n",
              " 'have',\n",
              " 'really',\n",
              " 'deep',\n",
              " 'pockets',\n",
              " ',',\n",
              " 'as',\n",
              " 'the',\n",
              " 'fine',\n",
              " 'payable',\n",
              " 'in',\n",
              " 'court',\n",
              " 'has',\n",
              " 'been',\n",
              " 'enhanced',\n",
              " 'to',\n",
              " 'Rs',\n",
              " '10,000',\n",
              " 'for',\n",
              " 'first-time',\n",
              " 'offenders',\n",
              " '.']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.tokenize(Doc1[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH5RpKdJgKwI"
      },
      "source": [
        "### Load pretrained model Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GKqEP4w5g3Sy"
      },
      "outputs": [],
      "source": [
        "vector_negative_bin_file_path  = \"/content/drive/MyDrive/Colab/chapter6_solution/Bai 6 - Code/GoogleNews-vectors-negative300.bin\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OJMwheuwg-Ux"
      },
      "outputs": [],
      "source": [
        "# Import the required modules\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Specify the correct function name\n",
        "model = KeyedVectors.load_word2vec_format(vector_negative_bin_file_path, binary=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdnOY-fNiuJj"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "EYknHffvhSKq"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    pattern = r'[^a-zA-z0-9\\s]'\n",
        "    text = re.sub(pattern, '', ''.join(text))\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)\n",
        "    return filtered_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a75dBrjbi5hZ"
      },
      "source": [
        "### Function to get the embedding vector for n dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wUNvvv3vhUPE"
      },
      "outputs": [],
      "source": [
        "def get_embedding(word):\n",
        "    try:\n",
        "        return model[word]\n",
        "    except KeyError:\n",
        "        return np.zeros(model.vector_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4GdkEwS6kP6E"
      },
      "outputs": [],
      "source": [
        "test_word_embedding = get_embedding(\"Union\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGmR1wE-iyWh",
        "outputId": "cad0e37b-34c9-4e3f-afd8-640d639ea973"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_word_embedding.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNZ0h_e7nKPK"
      },
      "source": [
        "Show vector của 1 từ (chiều dài vector là 300 do dùng pretrained có sẵn của Google)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbTZv6T5i0Gg",
        "outputId": "b9b17313-d334-40d9-d89f-226980ecd952"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 1.57226562e-01, -7.08007812e-02,  5.39550781e-02, -1.89208984e-02,\n",
              "        9.17968750e-02,  2.55126953e-02,  7.37304688e-02, -5.68847656e-02,\n",
              "        1.79687500e-01,  9.27734375e-02,  9.03320312e-02, -4.12109375e-01,\n",
              "       -8.30078125e-02, -1.45507812e-01, -2.37304688e-01, -3.68652344e-02,\n",
              "        8.74023438e-02, -2.77099609e-02,  1.13677979e-03,  8.30078125e-02,\n",
              "        3.57421875e-01, -2.61718750e-01,  7.47070312e-02, -8.10546875e-02,\n",
              "       -2.35595703e-02, -1.61132812e-01, -4.78515625e-02,  1.85546875e-01,\n",
              "       -3.97949219e-02, -1.58203125e-01, -4.37011719e-02, -1.11328125e-01,\n",
              "       -1.05957031e-01,  9.86328125e-02, -8.34960938e-02, -1.27929688e-01,\n",
              "       -1.39648438e-01, -1.86523438e-01, -5.71289062e-02, -1.17675781e-01,\n",
              "       -1.32812500e-01,  1.55639648e-02,  1.34765625e-01,  8.39843750e-02,\n",
              "       -9.03320312e-02, -4.12597656e-02, -2.51953125e-01, -2.27539062e-01,\n",
              "       -6.64062500e-02, -7.66601562e-02,  5.15136719e-02,  5.90820312e-02,\n",
              "        3.49609375e-01, -1.13769531e-01, -2.57568359e-02, -1.98242188e-01,\n",
              "        4.44335938e-02,  1.09863281e-01,  1.04003906e-01, -1.75781250e-01,\n",
              "        1.22558594e-01,  7.81250000e-02,  6.20117188e-02,  6.49414062e-02,\n",
              "       -1.73828125e-01, -1.11694336e-02,  1.88476562e-01,  3.34472656e-02,\n",
              "       -4.29687500e-02, -4.71191406e-02,  2.91015625e-01,  4.19921875e-02,\n",
              "        1.59179688e-01,  1.22558594e-01, -2.55859375e-01,  2.44140625e-01,\n",
              "        1.54296875e-01, -3.46679688e-02,  1.24023438e-01, -1.32812500e-01,\n",
              "        8.44726562e-02,  3.71093750e-02, -1.05468750e-01,  9.81445312e-02,\n",
              "       -8.23974609e-03,  5.34667969e-02, -1.96838379e-03,  9.03320312e-02,\n",
              "        1.30859375e-01, -1.57470703e-02, -2.40478516e-02, -3.29589844e-02,\n",
              "       -5.63964844e-02, -3.12500000e-01, -1.19140625e-01,  4.41894531e-02,\n",
              "       -1.82617188e-01, -2.20703125e-01,  8.39843750e-02, -2.15820312e-01,\n",
              "       -1.60156250e-01, -2.01171875e-01,  1.63085938e-01, -4.57763672e-05,\n",
              "        4.24804688e-02, -1.37695312e-01, -2.62451172e-02,  1.53320312e-01,\n",
              "       -1.07421875e-01, -1.34765625e-01, -3.73840332e-03, -1.51977539e-02,\n",
              "       -7.27539062e-02,  3.22265625e-02,  1.89453125e-01, -8.00781250e-02,\n",
              "        1.45507812e-01, -9.66796875e-02, -9.27734375e-02,  8.91113281e-03,\n",
              "       -4.27246094e-02, -9.76562500e-02,  3.29589844e-02, -7.95898438e-02,\n",
              "       -6.25000000e-02,  3.39355469e-02,  1.05590820e-02, -1.28906250e-01,\n",
              "        1.09863281e-01,  1.89453125e-01,  1.52343750e-01, -1.47460938e-01,\n",
              "       -3.86047363e-03,  1.75781250e-01, -4.58984375e-02, -1.02539062e-01,\n",
              "        6.34765625e-02, -9.86328125e-02,  1.87500000e-01,  3.97949219e-02,\n",
              "       -2.65625000e-01, -1.24023438e-01, -1.35742188e-01,  7.93457031e-03,\n",
              "        6.59179688e-02,  8.11767578e-03, -3.24707031e-02, -1.03759766e-02,\n",
              "       -1.90429688e-02, -8.20312500e-02,  2.06054688e-01,  1.40625000e-01,\n",
              "        1.93359375e-01,  2.91015625e-01, -9.17968750e-02, -1.40625000e-01,\n",
              "       -1.75781250e-01, -1.36718750e-01,  2.51464844e-02, -5.83496094e-02,\n",
              "       -1.84570312e-01,  3.10546875e-01,  7.17773438e-02, -1.01074219e-01,\n",
              "        1.08886719e-01, -2.23388672e-02,  1.50390625e-01, -7.03125000e-02,\n",
              "        1.24023438e-01,  2.21679688e-01, -1.97265625e-01, -6.05468750e-02,\n",
              "       -4.30297852e-03, -1.69921875e-01, -1.45507812e-01, -2.17773438e-01,\n",
              "        2.47070312e-01,  6.64062500e-02, -8.05664062e-02,  3.57421875e-01,\n",
              "       -8.20312500e-02, -7.87353516e-03,  1.08886719e-01, -5.32226562e-02,\n",
              "        3.00781250e-01, -2.37304688e-01,  1.61132812e-01,  1.59179688e-01,\n",
              "        1.69921875e-01, -9.52148438e-02,  5.20019531e-02, -6.22558594e-02,\n",
              "       -8.85009766e-03,  4.68750000e-02, -2.88085938e-02,  1.25000000e-01,\n",
              "        3.49121094e-02,  4.61425781e-02,  1.66015625e-02, -9.57031250e-02,\n",
              "       -1.48437500e-01, -1.64794922e-02, -2.22656250e-01, -2.51953125e-01,\n",
              "       -3.58886719e-02, -2.52685547e-02,  8.39233398e-05,  6.98242188e-02,\n",
              "        2.53906250e-01, -3.29589844e-02,  6.59179688e-02,  6.28662109e-03,\n",
              "       -7.86132812e-02, -3.01513672e-02, -9.47265625e-02,  1.25000000e-01,\n",
              "       -1.62109375e-01,  2.53906250e-01, -3.30078125e-01,  6.44531250e-02,\n",
              "       -9.09423828e-03,  7.12890625e-02,  3.99780273e-03, -4.41894531e-02,\n",
              "       -1.42822266e-02, -9.52148438e-03,  1.17675781e-01,  3.49609375e-01,\n",
              "       -2.90527344e-02,  1.86767578e-02,  3.46679688e-02,  1.89208984e-02,\n",
              "       -1.26953125e-01,  2.68554688e-02, -1.06933594e-01,  1.20117188e-01,\n",
              "       -2.69775391e-02, -5.07812500e-02, -1.76757812e-01,  3.95507812e-02,\n",
              "        1.35742188e-01, -9.61914062e-02, -1.98242188e-01, -1.86767578e-02,\n",
              "       -2.47802734e-02, -5.32226562e-02,  1.54296875e-01,  5.95703125e-02,\n",
              "        6.39648438e-02, -6.17675781e-02,  3.36914062e-02,  1.75781250e-01,\n",
              "        6.59179688e-02,  2.22656250e-01, -1.28906250e-01,  4.61425781e-02,\n",
              "       -2.57812500e-01,  6.78710938e-02,  6.29882812e-02, -1.15722656e-01,\n",
              "       -2.13867188e-01, -2.53906250e-01,  2.73437500e-02, -4.68750000e-02,\n",
              "        1.38671875e-01,  2.59765625e-01, -2.07031250e-01, -9.64355469e-03,\n",
              "       -5.22460938e-02, -7.20214844e-03,  8.49609375e-02, -2.49023438e-02,\n",
              "        1.94335938e-01, -7.37304688e-02,  1.22070312e-01, -3.49121094e-02,\n",
              "        1.41601562e-01, -1.38671875e-01,  7.61718750e-02, -1.93359375e-01,\n",
              "        1.64062500e-01, -2.78320312e-02, -1.45263672e-02,  1.44531250e-01,\n",
              "        1.75781250e-01, -1.70898438e-02,  1.26953125e-01,  3.39355469e-02,\n",
              "       -2.80761719e-02,  1.82617188e-01, -2.94921875e-01,  3.78417969e-02,\n",
              "       -1.63085938e-01,  1.73828125e-01, -1.01074219e-01, -1.49414062e-01,\n",
              "       -4.17480469e-02,  9.82666016e-03, -4.94384766e-03, -3.29589844e-02],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_embedding(\"house\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckJFAAyijCSs"
      },
      "source": [
        "### Tính vector cho câu bằng cách lấy trung bình của các embedding từ các từ trong câu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "64OG7hfihXuy"
      },
      "outputs": [],
      "source": [
        "out_dict =  {}\n",
        "for sentence in all_sentences:\n",
        "    average_vector = (np.mean(np.array([get_embedding(x) for x in nltk.word_tokenize(remove_stopwords(sentence.lower()))]), axis=0))\n",
        "    dict = { sentence : (average_vector) }\n",
        "    out_dict.update(dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc5r-w-Vh4vD",
        "outputId": "d9b4c27d-c8dc-471a-a3c9-06d6488e8888"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.': array([-0.00752952,  0.07640769,  0.02021651,  0.0393538 , -0.06667813,\n",
              "        -0.09641058,  0.0038473 , -0.08695915,  0.06166562,  0.05776978,\n",
              "        -0.01717099, -0.07339061, -0.01688454,  0.02896396, -0.14146839,\n",
              "         0.03586648,  0.08766868,  0.04445579,  0.03018492, -0.03743397,\n",
              "         0.07872425, -0.0311307 , -0.0437896 , -0.02006392,  0.09745927,\n",
              "        -0.05626887, -0.08198131,  0.06809304,  0.03912354, -0.03560014,\n",
              "        -0.01045366, -0.06907515,  0.01930514,  0.08539789,  0.02101829,\n",
              "        -0.08427767,  0.02317116, -0.00695523, -0.01170072,  0.05518185,\n",
              "         0.04779608, -0.03513406,  0.13249796, -0.02304086, -0.09093406,\n",
              "        -0.0787298 ,  0.00950484,  0.02489818, -0.0392567 ,  0.01530179,\n",
              "        -0.03363592,  0.04622442,  0.03904031,  0.0240534 ,  0.0440542 ,\n",
              "         0.02402566, -0.07901556,  0.01442719, -0.03246515, -0.06742165,\n",
              "         0.00476178,  0.05848555, -0.12312456, -0.05578024, -0.05742437,\n",
              "         0.03038996, -0.0602306 ,  0.06781561, -0.04309914, -0.01353316,\n",
              "        -0.01314198, -0.02096558,  0.09695851,  0.08252681, -0.07706243,\n",
              "        -0.02125619,  0.05103198,  0.06786555,  0.01880264, -0.03313654,\n",
              "        -0.011519  , -0.07489569, -0.0352485 ,  0.06833163,  0.04473877,\n",
              "        -0.03005149, -0.07837   ,  0.11494585,  0.01001115,  0.04899458,\n",
              "         0.08946471, -0.00096547,  0.03410756, -0.05302637, -0.05280928,\n",
              "        -0.05064253,  0.02014195, -0.07260964, -0.01057018, -0.08119895,\n",
              "        -0.02022483, -0.05879628,  0.06052468, -0.00854215,  0.05696947,\n",
              "        -0.0527316 ,  0.05765984, -0.00357264,  0.08356406, -0.04562109,\n",
              "        -0.04204767, -0.05286061, -0.05968822, -0.00373563,  0.12681926,\n",
              "        -0.00320157,  0.04113353, -0.02481634,  0.00703569,  0.02208363,\n",
              "        -0.00164795,  0.09790039, -0.07759718,  0.08210494,  0.0452267 ,\n",
              "        -0.0357777 , -0.05480853, -0.07980347,  0.10293302, -0.00154322,\n",
              "         0.03880726, -0.01202947, -0.06956898, -0.01801647, -0.08555187,\n",
              "        -0.00281871, -0.02129988,  0.01447088, -0.02033164,  0.08818193,\n",
              "        -0.03141091, -0.01966997, -0.03793612,  0.01455099, -0.04768233,\n",
              "        -0.00837985, -0.07003541,  0.03558904, -0.05600669, -0.0423473 ,\n",
              "         0.15447166, -0.02197196, -0.08487216, -0.00178112, -0.01375094,\n",
              "        -0.04823442, -0.04774475, -0.04318099, -0.04120428, -0.02675143,\n",
              "         0.05237579,  0.04302979,  0.0517911 , -0.0352863 , -0.04547501,\n",
              "        -0.05238758,  0.0744296 , -0.00442227, -0.00651966, -0.04368245,\n",
              "        -0.0959972 , -0.07083407, -0.02324919, -0.0548609 , -0.00432517,\n",
              "        -0.08271686,  0.03671958, -0.05489696, -0.06446145,  0.01506701,\n",
              "        -0.0348809 ,  0.00343461, -0.0152255 , -0.0029009 , -0.05729814,\n",
              "        -0.00236685, -0.02087402,  0.04626742, -0.02065208,  0.06466675,\n",
              "        -0.01332231,  0.04156563, -0.04883367,  0.00209219, -0.01197399,\n",
              "         0.04686945,  0.01095442, -0.0285589 , -0.02439187, -0.01048556,\n",
              "        -0.00307811,  0.03506747,  0.02422957, -0.02300262,  0.03957852,\n",
              "         0.02234164, -0.00039395,  0.00356293,  0.04154275, -0.01513672,\n",
              "         0.01778065,  0.01507776,  0.02065763,  0.08180376, -0.07941229,\n",
              "         0.03993919,  0.04743203,  0.06640902, -0.07248202,  0.01205722,\n",
              "        -0.02723347, -0.04358742,  0.02675004,  0.02642926,  0.08423753,\n",
              "        -0.04945096,  0.07050254,  0.06695661,  0.03937669, -0.01392781,\n",
              "        -0.00332642,  0.0002183 ,  0.0330866 ,  0.04143871, -0.06112307,\n",
              "         0.01025945,  0.03465687, -0.03927196,  0.06687234, -0.03093214,\n",
              "         0.11639058, -0.02599265, -0.00268832, -0.10023915, -0.01767627,\n",
              "         0.02089552, -0.04007235,  0.05488378,  0.06160199, -0.07754794,\n",
              "         0.07392328,  0.07656028, -0.01812467,  0.07817216,  0.04694158,\n",
              "        -0.04440793,  0.08182872, -0.00971846, -0.02105435, -0.02262185,\n",
              "         0.00930439, -0.0141612 , -0.02853671,  0.01674028,  0.00858099,\n",
              "         0.05932617, -0.06364163,  0.03675426, -0.10288724, -0.04609819,\n",
              "        -0.02054665,  0.08031117, -0.01951738,  0.09371914,  0.04293268,\n",
              "        -0.0503651 , -0.02221957, -0.04171475, -0.08646532,  0.07087049,\n",
              "        -0.02614663,  0.03722668,  0.09440197,  0.04437256, -0.01022061,\n",
              "         0.01408785, -0.05907093,  0.00736028,  0.09880759,  0.07261658,\n",
              "        -0.05600947,  0.04385792, -0.04696881, -0.02650751, -0.04739796,\n",
              "         0.0338844 ,  0.01069502, -0.06295499,  0.03325306, -0.01043424]),\n",
              " 'Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.': array([ 0.03671631,  0.02628906,  0.07552246,  0.09806091, -0.13878418,\n",
              "         0.03660522,  0.08276031, -0.01799072,  0.04226807,  0.02133545,\n",
              "        -0.01629883, -0.1150293 , -0.06875244,  0.02828857, -0.0744043 ,\n",
              "         0.05834473, -0.07832092,  0.16145508, -0.0005555 , -0.1176416 ,\n",
              "        -0.0662085 ,  0.02032227, -0.09220612,  0.07047119,  0.04085938,\n",
              "        -0.07560852, -0.04737549,  0.02337891,  0.00390869, -0.08439453,\n",
              "        -0.01909393, -0.0543457 , -0.05770996, -0.00987793, -0.03687988,\n",
              "        -0.09939941, -0.07626221, -0.01834961,  0.05221191,  0.00974762,\n",
              "         0.07427002,  0.07186646,  0.09092163,  0.08909134, -0.03683105,\n",
              "        -0.06796875, -0.04703125,  0.08603516, -0.13201172,  0.04408356,\n",
              "        -0.00389435, -0.10378418, -0.0441626 , -0.06796387, -0.0636084 ,\n",
              "         0.10358267, -0.05449371, -0.19697021,  0.00951591, -0.03915405,\n",
              "        -0.02369781,  0.01540802, -0.01838379, -0.00294434, -0.05245605,\n",
              "         0.04599609, -0.06522705,  0.19167603, -0.05977051, -0.03453125,\n",
              "         0.01488312, -0.10781036,  0.03795166,  0.00172852, -0.08492676,\n",
              "        -0.03116577,  0.09625   ,  0.04060425,  0.03437988,  0.05440063,\n",
              "         0.01270325,  0.03618652,  0.10004761,  0.05489014,  0.02603516,\n",
              "        -0.09934814, -0.05911926,  0.19569336,  0.02360107,  0.08256958,\n",
              "         0.08014893, -0.03104004, -0.07529297, -0.07560791,  0.01552734,\n",
              "        -0.0117334 ,  0.03431641, -0.01211182,  0.09364258, -0.00978271,\n",
              "         0.01714111, -0.02435547, -0.0137207 , -0.00927979,  0.02582031,\n",
              "         0.05141235, -0.03633301, -0.06144653,  0.15360352, -0.02409058,\n",
              "        -0.11047424, -0.01209473,  0.00750488,  0.00849609,  0.07347778,\n",
              "         0.08622559, -0.01179861, -0.02863281,  0.11573975,  0.03656128,\n",
              "        -0.14498535,  0.02331787, -0.01365723,  0.12352142, -0.07273605,\n",
              "         0.0501474 , -0.06170898, -0.03255615,  0.03859009,  0.07886047,\n",
              "        -0.01121582, -0.07210693, -0.11975708,  0.0413636 ,  0.03791992,\n",
              "        -0.06959473,  0.0702002 ,  0.00815918, -0.03396484, -0.01710327,\n",
              "         0.08525879, -0.06010254, -0.06188965,  0.02697754,  0.00302734,\n",
              "        -0.01144104,  0.0997998 ,  0.08984375, -0.07783203, -0.03130371,\n",
              "         0.07895142,  0.02234497, -0.0864209 ,  0.126521  , -0.02293945,\n",
              "        -0.0714624 , -0.10546204, -0.04070312, -0.07266602, -0.04245117,\n",
              "        -0.08873535,  0.00231323, -0.06337402,  0.00377563, -0.00510353,\n",
              "         0.07641083,  0.04804199, -0.06124268,  0.02434143,  0.00398315,\n",
              "        -0.07356079,  0.06097412, -0.06758911,  0.0176062 ,  0.08528809,\n",
              "        -0.02130859,  0.02333252, -0.10712158, -0.12833252, -0.08173737,\n",
              "        -0.07268066, -0.10395508,  0.01026611, -0.14332886,  0.04627502,\n",
              "         0.00840576, -0.08141357,  0.02497559,  0.05015869,  0.05914307,\n",
              "        -0.08667969, -0.09967773, -0.01505371,  0.0191626 , -0.03034912,\n",
              "         0.04416992,  0.01658203, -0.13347656, -0.05233948, -0.08290039,\n",
              "        -0.00143555,  0.04765533,  0.01779053,  0.02892029, -0.03135658,\n",
              "        -0.04532593,  0.08747681, -0.0319043 , -0.07655762, -0.041521  ,\n",
              "        -0.05858551, -0.04614243, -0.08888969,  0.04319092, -0.00343262,\n",
              "         0.06546387,  0.10087433,  0.0818634 , -0.08977539, -0.00333008,\n",
              "         0.04717529, -0.04434814, -0.05525879, -0.03685547, -0.03515869,\n",
              "        -0.04931152,  0.00907471, -0.00396729,  0.02128418,  0.04592407,\n",
              "         0.03173828, -0.04367676,  0.00899323, -0.03428467, -0.00665771,\n",
              "        -0.10150391,  0.05506104, -0.03298584,  0.05916077, -0.00770447,\n",
              "         0.03390381,  0.00245178, -0.00715088, -0.04341553, -0.00107178,\n",
              "        -0.04320801,  0.02833862,  0.12857422, -0.0371283 , -0.04071686,\n",
              "        -0.07069824, -0.03015381, -0.02858887,  0.03360779,  0.02124756,\n",
              "        -0.14345337, -0.03186951,  0.03109619, -0.06171021, -0.00932129,\n",
              "         0.03614258, -0.07625244, -0.06279785,  0.07858154,  0.03361938,\n",
              "         0.0633374 , -0.00657501, -0.03530273, -0.13596085, -0.00318848,\n",
              "        -0.08134766,  0.00689941, -0.03379486,  0.01974304,  0.02456787,\n",
              "        -0.06312988, -0.02886292, -0.05875   ,  0.01759521, -0.01011719,\n",
              "        -0.09027679,  0.05251709,  0.08329834,  0.06853516, -0.01247162,\n",
              "        -0.08229492, -0.00379639,  0.03966064,  0.08342167,  0.1265918 ,\n",
              "        -0.16033691,  0.00831394, -0.00988403, -0.00771912, -0.00638184,\n",
              "         0.00808838,  0.02894287, -0.04137512,  0.0505957 , -0.01468689]),\n",
              " 'He points out that public transport is very good in Mumbai and New Delhi, where there is a good network of suburban and metro rail systems.': array([-0.02435772,  0.04364014,  0.06268076,  0.14637169, -0.0079064 ,\n",
              "        -0.06754112, -0.14038086, -0.01328806,  0.04539138,  0.08156175,\n",
              "        -0.01361553,  0.01603112,  0.01240011, -0.09572191, -0.04253681,\n",
              "         0.01367657,  0.04514137,  0.07946308, -0.00133338, -0.03790753,\n",
              "        -0.01416016, -0.05218623,  0.03725022,  0.05994591,  0.07136418,\n",
              "         0.02364878, -0.17354642,  0.09457163,  0.02470985, -0.0817965 ,\n",
              "         0.05033053, -0.10643592,  0.01585036, -0.06426533, -0.02034877,\n",
              "        -0.07916729, -0.06465736, -0.01655461,  0.07770245,  0.0079064 ,\n",
              "        -0.03109976, -0.05992244,  0.13080303,  0.09084614, -0.05000599,\n",
              "        -0.0768503 ,  0.02835787,  0.01271879, -0.04379507,  0.11972281,\n",
              "         0.04092642,  0.12637094,  0.04154117, -0.00246488, -0.122642  ,\n",
              "        -0.04306265, -0.15768197, -0.01853591,  0.05303955, -0.056758  ,\n",
              "        -0.0500547 , -0.00990636, -0.18726525, -0.06217605,  0.01079911,\n",
              "         0.02901517, -0.1205773 ,  0.08513935, -0.05588473,  0.1201923 ,\n",
              "        -0.02408072,  0.05883789,  0.06933594,  0.01133669, -0.16045673,\n",
              "        -0.07543945, -0.00559645,  0.06620671, -0.02292105, -0.00908015,\n",
              "        -0.04192646,  0.07655687,  0.02009465, -0.03164438,  0.0549692 ,\n",
              "         0.00287188, -0.11234225,  0.10435604,  0.01090182,  0.08448204,\n",
              "         0.05737539, -0.03559758, -0.06066249, -0.02713834, -0.09590971,\n",
              "        -0.00129817,  0.03356934, -0.0497906 ,  0.06161734,  0.00368617,\n",
              "         0.04050739,  0.01483154,  0.02848933,  0.0709745 , -0.0401893 ,\n",
              "        -0.04312368,  0.02927575,  0.01705698,  0.05111225, -0.02889663,\n",
              "        -0.0263085 , -0.05586595, -0.01832933, -0.10235126,  0.16160819,\n",
              "         0.00675143,  0.02492347, -0.07037823,  0.09178749,  0.07430572,\n",
              "        -0.14409226,  0.0025177 , -0.18442008, -0.02378963,  0.00820219,\n",
              "         0.02474976, -0.01197228, -0.03493089,  0.05589881, -0.01508038,\n",
              "        -0.03033917, -0.01472356,  0.01735276, -0.05519456, -0.00239211,\n",
              "        -0.07814144,  0.11480244, -0.04205792, -0.01000038,  0.08985783,\n",
              "        -0.00582299, -0.12862924,  0.03302002,  0.0544997 , -0.13739483,\n",
              "        -0.06727013, -0.07526104, -0.05711071,  0.02788368, -0.04811448,\n",
              "         0.15245643, -0.02137698, -0.01056378,  0.02047025, -0.05665706,\n",
              "        -0.12491549,  0.01747953, -0.06067834, -0.02671462, -0.05367103,\n",
              "        -0.0338886 ,  0.0148333 ,  0.03629714,  0.04163537,  0.01956177,\n",
              "         0.0308744 ,  0.0202355 , -0.21302678,  0.00614108, -0.04971079,\n",
              "        -0.1848614 , -0.07573055, -0.04329975, -0.05187049,  0.05879094,\n",
              "         0.0095966 ,  0.03578655, -0.17339852, -0.08212046, -0.07055664,\n",
              "         0.00137094,  0.01005672, -0.11194786, -0.06144362,  0.05926279,\n",
              "         0.02745643, -0.10806157,  0.02577092,  0.05149489,  0.02875225,\n",
              "        -0.04929   , -0.05265925, -0.1591703 ,  0.02593525, -0.00665283,\n",
              "         0.02172147, -0.0537485 , -0.09163255, -0.05511944, -0.1089994 ,\n",
              "        -0.08145376,  0.04820838,  0.08958083,  0.01285494, -0.04534443,\n",
              "        -0.08756197, -0.03728074, -0.13604149,  0.04249015,  0.01538086,\n",
              "        -0.08343036,  0.00642043, -0.03033917, -0.0466872 , -0.1574707 ,\n",
              "         0.03987474,  0.01862042,  0.12663856, -0.01508977,  0.07029372,\n",
              "         0.04983755, -0.09718014, -0.00201416,  0.05489526, -0.06671612,\n",
              "        -0.12959641, -0.07950182,  0.0671105 , -0.0086576 , -0.01406626,\n",
              "        -0.00317383, -0.08256413,  0.05232121,  0.06276762, -0.0288532 ,\n",
              "         0.06032269,  0.08064152, -0.07104316,  0.04922074, -0.01908757,\n",
              "         0.17267433,  0.04258845,  0.05277428, -0.07036297, -0.08778264,\n",
              "         0.03127348, -0.01366249,  0.07185246, -0.10357901, -0.08501728,\n",
              "         0.0450909 ,  0.1271597 ,  0.06771147,  0.12088717,  0.09819148,\n",
              "        -0.12346943,  0.04181612,  0.02008291, -0.1427401 , -0.10637958,\n",
              "        -0.03432993, -0.00270433, -0.0094047 ,  0.05427434,  0.11579777,\n",
              "         0.12336613, -0.07041579, -0.09986525, -0.12997201, -0.01277513,\n",
              "        -0.08640348, -0.02280837,  0.04217999, -0.04572942,  0.08246399,\n",
              "        -0.12526292,  0.01187838, -0.03334397,  0.04562613,  0.03204111,\n",
              "        -0.08362051,  0.04613319, -0.00543095,  0.03903433, -0.06871737,\n",
              "         0.02592586, -0.10258602,  0.01393949,  0.02416757,  0.00203764,\n",
              "        -0.06006329,  0.01384559, -0.04208609,  0.04090295, -0.03375714,\n",
              "        -0.06912701, -0.03608117, -0.01934814, -0.00802495, -0.04592191],\n",
              "       dtype=float32),\n",
              " 'But the man behind the wickets at the other end was watching just as keenly. With an affirmative nod from Dhoni, India captain Rohit Sharma promptly asked for a review. Sure enough, the ball would have clipped the top of middle and leg.': array([-9.14287567e-03,  5.33491783e-02,  1.38575239e-02,  3.11838780e-02,\n",
              "        -5.38126640e-02, -1.23808540e-01,  5.48985787e-02, -1.07878365e-01,\n",
              "         8.28742981e-02,  4.60111313e-02,  1.45950317e-02, -7.83143044e-02,\n",
              "         2.18963623e-03,  4.56301384e-02, -9.61774215e-02,  6.20514564e-02,\n",
              "         4.40572090e-02,  4.80155945e-02,  9.27734375e-03, -1.03327436e-02,\n",
              "         1.16189325e-03,  2.83819828e-02,  8.42944011e-02, -5.18302917e-02,\n",
              "         5.76267242e-02, -9.23980102e-02, -1.04667664e-01,  8.69344100e-02,\n",
              "         1.32321671e-01, -1.31289167e-02, -7.51037598e-02,  5.19434595e-03,\n",
              "        -3.00966892e-02, -5.84173203e-03, -3.41900177e-02, -1.15369158e-02,\n",
              "        -1.22146606e-02,  1.11821489e-02,  3.52528878e-02,  5.69992065e-02,\n",
              "         3.90103646e-02, -1.00697838e-01,  2.23932907e-01, -4.11402397e-02,\n",
              "        -1.92591343e-02, -7.01681757e-03, -1.72042400e-02, -5.25716133e-02,\n",
              "         3.92303467e-02,  1.09558105e-02, -5.58319092e-02,  8.18328857e-02,\n",
              "         6.49878159e-02, -3.50634269e-02,  2.81270337e-03, -7.14111328e-03,\n",
              "        -1.22006738e-03, -6.13581352e-02,  5.63290901e-02, -1.00330986e-01,\n",
              "        -5.44474907e-02,  6.61617145e-02, -1.35833740e-01, -1.06493630e-01,\n",
              "        -1.56402588e-02,  4.30959053e-02, -3.35306339e-02,  3.61048393e-02,\n",
              "         3.27962227e-02,  8.04901123e-02,  1.91980992e-02,  6.38326025e-03,\n",
              "         3.44746895e-02, -4.00136299e-02, -2.10647583e-01, -1.04085289e-01,\n",
              "         3.91044617e-02,  5.81525154e-02,  9.32280254e-03, -4.36782837e-04,\n",
              "         3.37117501e-02,  4.53567505e-02, -5.68898534e-03, -3.34154777e-02,\n",
              "         4.70434837e-02,  1.65557861e-03, -5.92651367e-02,  5.55432625e-02,\n",
              "         4.75718193e-02,  3.68258171e-02,  3.97491455e-02,  4.44361381e-02,\n",
              "        -5.05383797e-02,  4.67122383e-02, -2.35684719e-02, -6.20358773e-02,\n",
              "         1.76747644e-03, -9.97416209e-03, -5.68784066e-02, -3.52910347e-02,\n",
              "        -1.10548334e-02, -7.51063004e-02,  4.86577339e-02,  7.41799688e-03,\n",
              "        -1.54177351e-02, -2.32798252e-02, -1.09783811e-02, -3.08136940e-02,\n",
              "         4.57496643e-02, -3.48339081e-02, -2.77303066e-02, -4.65850830e-02,\n",
              "         9.10886098e-03, -2.25639343e-03,  9.10205841e-02, -5.60951233e-03,\n",
              "        -2.75065098e-02, -1.20544434e-03,  1.00055695e-01,  4.10970040e-02,\n",
              "        -9.18324813e-02,  6.06486015e-02, -5.22359200e-02,  5.61898537e-02,\n",
              "        -6.03510551e-02, -2.11995449e-02, -3.48409005e-02, -6.87789917e-02,\n",
              "        -7.10996008e-03,  5.30344658e-02, -9.75023881e-02, -4.72106934e-02,\n",
              "        -4.40394096e-02, -3.81290130e-02, -5.37414551e-02, -5.48216514e-02,\n",
              "        -1.00145340e-02,  4.89962883e-02,  1.49555206e-02,  1.46044418e-01,\n",
              "         9.34807435e-02, -8.13406333e-02,  1.46554308e-02, -1.49497986e-02,\n",
              "        -9.90228653e-02,  7.54140243e-02, -7.96017647e-02, -2.12427769e-02,\n",
              "         2.37782791e-04, -8.91621877e-03,  3.82664986e-02,  1.95007324e-02,\n",
              "        -9.05660018e-02,  4.15840149e-02, -3.18908691e-03, -1.57063808e-02,\n",
              "        -9.25464630e-02, -5.79350777e-02, -3.98635864e-03, -2.61370335e-02,\n",
              "        -8.56208801e-02, -3.76663208e-02,  1.01064049e-01, -1.95973720e-02,\n",
              "        -3.44060250e-02, -1.44688919e-01,  8.86637345e-02, -1.76137295e-02,\n",
              "        -9.87752248e-03, -7.23743439e-03, -1.12859093e-01,  1.06302893e-03,\n",
              "         6.85056066e-03, -9.65652466e-02, -5.49125671e-02, -6.53978959e-02,\n",
              "         1.21173859e-01, -1.12396240e-01, -5.85123710e-02, -6.55272827e-02,\n",
              "        -1.82215367e-02,  7.17544556e-03,  7.85579681e-02, -3.49432640e-02,\n",
              "        -1.97614040e-02,  6.39864579e-02,  5.54250069e-02,  7.09787989e-03,\n",
              "         9.65423584e-02, -2.14894608e-04, -2.78879795e-02,  1.10931396e-02,\n",
              "        -1.80409756e-02,  1.82228088e-02,  6.38478622e-02,  5.14758416e-02,\n",
              "         5.29117584e-02,  2.20845547e-02,  3.95663595e-03, -5.46442680e-02,\n",
              "        -1.65659580e-02,  1.08133955e-02, -2.11385097e-02, -4.38334160e-02,\n",
              "        -7.27844238e-03, -7.75960311e-02, -2.67995205e-02, -1.51977539e-02,\n",
              "         5.41890450e-02,  3.42814135e-03, -3.73160057e-02,  6.92081451e-02,\n",
              "        -8.19168091e-02, -7.58457184e-03, -1.20583214e-01, -7.97138214e-02,\n",
              "         1.43254595e-02,  1.59161892e-02, -1.05428062e-01, -1.36667890e-02,\n",
              "        -1.84961949e-02,  1.50794983e-02, -5.46938591e-02,  2.80316677e-02,\n",
              "         5.37885018e-02, -8.49914551e-03,  1.06150053e-01, -9.14573669e-02,\n",
              "         5.72621040e-02, -4.01306152e-02, -2.64336262e-02, -2.11175289e-02,\n",
              "        -7.04447448e-04, -3.74298096e-02,  8.74413624e-02,  1.89386997e-02,\n",
              "         1.92324314e-02, -6.16381951e-02,  6.94986954e-02,  3.63388062e-02,\n",
              "         3.96518707e-02,  8.48261546e-03,  4.68285866e-02, -1.18649960e-01,\n",
              "        -2.27737427e-02,  3.94490547e-02, -9.57234669e-03, -1.78464260e-02,\n",
              "         1.79532375e-02,  6.08825684e-03,  6.42242432e-02,  2.79083252e-02,\n",
              "         1.05010986e-01,  5.94387054e-02,  6.72302246e-02, -4.98549156e-02,\n",
              "        -1.87737141e-02,  4.89355735e-02, -7.62481689e-02, -5.13966866e-02,\n",
              "        -1.99985504e-02,  1.36533096e-01, -1.88496914e-02, -6.30645752e-02,\n",
              "         6.06718063e-02,  7.73531571e-02, -3.89811210e-02,  7.50271464e-03,\n",
              "        -1.44348145e-02, -3.75251770e-02, -1.64362583e-02,  6.53142929e-02,\n",
              "         4.37602997e-02,  2.04111729e-02,  6.60629272e-02, -6.81228638e-02,\n",
              "        -3.91718559e-02, -1.32140473e-01, -5.20577431e-02,  6.83504716e-02,\n",
              "         6.20355606e-02, -2.31622066e-02, -4.04040031e-02,  1.03407420e-01,\n",
              "        -3.33531685e-02, -2.43314113e-02, -1.28936768e-02,  9.00522843e-02,\n",
              "         5.58484383e-02,  5.89866638e-02,  1.65812171e-03, -2.38409042e-02,\n",
              "         4.40470362e-03, -4.17213440e-02, -1.07612805e-02,  2.53346767e-02,\n",
              "        -5.38686104e-02, -4.96444702e-02, -4.05591317e-02,  2.61484776e-02],\n",
              "       dtype=float32)}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIFtIPHpjo6J"
      },
      "source": [
        "### Function to calculate the similarity between the **query vector** and **document vector**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "1llMd7oMieXe"
      },
      "outputs": [],
      "source": [
        "def get_similarity(query_embedding, average_vector_doc):\n",
        "    sim = [(1 - scipy.spatial.distance.cosine(query_embedding, average_vector_doc))]\n",
        "    return sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "zhiQ2RxMihLL"
      },
      "outputs": [],
      "source": [
        "# Rank all the documents based on the similarity to get relevant docs\n",
        "def ranked_documents(query):\n",
        "    #Tính vector trung bình cho chuỗi truy vấn\n",
        "    query_words = np.mean(np.array([get_embedding(x) for x in nltk.word_tokenize(remove_stopwords(query.lower()))],dtype=float), axis=0)\n",
        "    rank = []\n",
        "    for k,v in out_dict.items():\n",
        "        rank.append((k, get_similarity(query_words, v)))\n",
        "    rank = sorted(rank,key=lambda t: t[1], reverse=True)\n",
        "    print('Ranked Documents :')\n",
        "    return rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlscLsqGlIQL",
        "outputId": "62ae132f-36cd-4ced-8df3-f7cd5fccb4b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1.0]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_similarity([1,2,3], [1,2,3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMGi-RT4imUc",
        "outputId": "d9df1842-bccc-41d0-8c56-d887d26903e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranked Documents :\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.',\n",
              "  [0.5257626816961933]),\n",
              " ('He points out that public transport is very good in Mumbai and New Delhi, where there is a good network of suburban and metro rail systems.',\n",
              "  [0.27723365002179334]),\n",
              " ('But the man behind the wickets at the other end was watching just as keenly. With an affirmative nod from Dhoni, India captain Rohit Sharma promptly asked for a review. Sure enough, the ball would have clipped the top of middle and leg.',\n",
              "  [0.21373832056834186]),\n",
              " ('Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.',\n",
              "  [0.1754548155463025])]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ranked_documents(\"With the Union cabinet approving\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA18-H7Pmu-p",
        "outputId": "57bff637-4cce-47d9-fcd5-320cd07d3ed1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranked Documents :\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.',\n",
              "  [0.8812577269377971]),\n",
              " ('But the man behind the wickets at the other end was watching just as keenly. With an affirmative nod from Dhoni, India captain Rohit Sharma promptly asked for a review. Sure enough, the ball would have clipped the top of middle and leg.',\n",
              "  [0.47518011636993696]),\n",
              " ('He points out that public transport is very good in Mumbai and New Delhi, where there is a good network of suburban and metro rail systems.',\n",
              "  [0.4419815397236223]),\n",
              " ('Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.',\n",
              "  [0.37360628531744333])]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ranked_documents('With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSmKyB7ai_aG",
        "outputId": "4a8107e4-e2a6-4ec8-c242-3b3daf90d9e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranked Documents :\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.',\n",
              "  [1.0]),\n",
              " ('But the man behind the wickets at the other end was watching just as keenly. With an affirmative nod from Dhoni, India captain Rohit Sharma promptly asked for a review. Sure enough, the ball would have clipped the top of middle and leg.',\n",
              "  [0.5105212145035003]),\n",
              " ('He points out that public transport is very good in Mumbai and New Delhi, where there is a good network of suburban and metro rail systems.',\n",
              "  [0.48402211451969834]),\n",
              " ('Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.',\n",
              "  [0.39162706165865124])]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ranked_documents(Doc1[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhtlVIr8qD8a"
      },
      "source": [
        "### Cải tiến"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB_KkWzOqK5C",
        "outputId": "4c1dc585-9481-4f1f-b676-a8ca029208c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting annoy\n",
            "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/647.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.3-cp311-cp311-linux_x86_64.whl size=553317 sha256=28c42283aca1123d3713b8e8bf08cdf9d27a0ad06eba58b60640469f7a09b3f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/e5/58/0a3e34b92bedf09b4c57e37a63ff395ade6f6c1099ba59877c\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.3\n"
          ]
        }
      ],
      "source": [
        "!pip install annoy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IRSsNnuqTj6",
        "outputId": "68cdfd95-297f-43e9-b641-a2c4e298998c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building document vectors...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import scipy.spatial.distance\n",
        "from annoy import AnnoyIndex\n",
        "import pickle # Để lưu map index <-> câu\n",
        "\n",
        "# Giả sử bạn đã có hàm get_embedding và hàm remove_stopwords\n",
        "# Giả sử all_sentences là list các câu của bạn\n",
        "# Giả sử EMBEDDING_DIM là kích thước của vector embedding\n",
        "\n",
        "print(\"Building document vectors...\")\n",
        "out_dict = {}\n",
        "doc_vectors = []\n",
        "doc_indices = [] # Lưu thứ tự gốc của câu\n",
        "\n",
        "for i, sentence in enumerate(all_sentences):\n",
        "    tokens = nltk.word_tokenize(remove_stopwords(sentence.lower()))\n",
        "    if not tokens:\n",
        "        continue\n",
        "\n",
        "    # Tính vector trung bình, đảm bảo không bị lỗi nếu chỉ có 1 token\n",
        "    sentence_vector = np.mean(np.array([get_embedding(x) for x in tokens]), axis=0)\n",
        "    # Kiểm tra xem vector có hợp lệ không (tránh NaN nếu get_embedding lỗi)\n",
        "    if not np.isnan(sentence_vector).any():\n",
        "        out_dict[sentence] = sentence_vector\n",
        "        doc_vectors.append(sentence_vector)\n",
        "        doc_indices.append(i) # Lưu index gốc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JBjDw0bq1Zp",
        "outputId": "292c5656-39f7-42a6-b5fc-225835441f20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out_dict['With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w7NPGj0qipK",
        "outputId": "6c43c9d3-ac2e-4416-84c2-7a3acbfce2c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building Annoy index...\n"
          ]
        }
      ],
      "source": [
        "# --- Xây dựng Annoy Index ---\n",
        "print(\"Building Annoy index...\")\n",
        "embedding_dim = 300 # Thay bằng kích thước thật của embedding\n",
        "annoy_index = AnnoyIndex(embedding_dim, 'angular') # 'angular' tương ứng với cosine distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0ywjnIpr907"
      },
      "outputs": [],
      "source": [
        "save_path_index = '/content/mydocuments.ann'\n",
        "save_path_map = '/content/index_map.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQMQknRzrYe5",
        "outputId": "4d733add-3aa8-4cf9-b2b0-cbc8d986385e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving index to: /content/mydocuments.ann\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tạo map từ index của Annoy về câu gốc\n",
        "index_to_sentence_map = {}\n",
        "for annoy_idx, original_idx in enumerate(doc_indices):\n",
        "    sentence = all_sentences[original_idx]\n",
        "    vector = out_dict[sentence]\n",
        "    annoy_index.add_item(annoy_idx, vector)\n",
        "    index_to_sentence_map[annoy_idx] = sentence\n",
        "\n",
        "# Xây dựng index - số cây (n_trees) càng lớn càng chính xác nhưng chậm hơn\n",
        "# và tốn bộ nhớ hơn. Cần thử nghiệm để chọn giá trị phù hợp.\n",
        "annoy_index.build(100)\n",
        "print(f\"Saving index to: {save_path_index}\")\n",
        "annoy_index.save(save_path_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zl5aVspBsXTy"
      },
      "outputs": [],
      "source": [
        "def ranked_documents_annoy(query, num_results=10):\n",
        "    # Tính vector trung bình cho chuỗi truy vấn\n",
        "    query_tokens = nltk.word_tokenize(query.lower())\n",
        "    if not query_tokens:\n",
        "         print(\"Query is empty or contains only stopwords.\")\n",
        "         return []\n",
        "    # Lấy embedding, đảm bảo dtype=float để tránh lỗi mean với object\n",
        "    query_embeddings = [get_embedding(x) for x in query_tokens if get_embedding(x) is not None] # Bỏ qua từ không có embedding\n",
        "    if not query_embeddings:\n",
        "        print(\"No valid embeddings found for query tokens.\")\n",
        "        return []\n",
        "    query_vector = np.mean(np.array(query_embeddings, dtype=float), axis=0)\n",
        "\n",
        "    if np.isnan(query_vector).any():\n",
        "         print(\"Could not compute a valid query vector.\")\n",
        "         return []\n",
        "\n",
        "    # Tìm kiếm các hàng xóm gần nhất bằng Annoy\n",
        "    # get_nns_by_vector trả về list các index của Annoy\n",
        "    # include_distances=True trả về cả khoảng cách (không phải similarity)\n",
        "    neighbor_indices, distances = annoy_index.get_nns_by_vector(\n",
        "        query_vector,\n",
        "        num_results,\n",
        "        include_distances=True\n",
        "    )\n",
        "\n",
        "    # Lấy lại câu gốc và tính similarity (nếu cần chính xác)\n",
        "    # Hoặc chỉ cần sắp xếp theo distance trả về từ Annoy (distance nhỏ -> similarity cao)\n",
        "    results = []\n",
        "    for annoy_idx, dist in zip(neighbor_indices, distances):\n",
        "        sentence = index_to_sentence_map[annoy_idx]\n",
        "        # Annoy 'angular' distance d = sqrt(2*(1-cos(u,v)))\n",
        "        # Nên cos(u,v) = 1 - (d^2)/2\n",
        "        similarity = 1 - (dist**2) / 2\n",
        "        results.append((sentence, similarity))\n",
        "\n",
        "    # Sắp xếp lại theo similarity giảm dần (vì Annoy trả về theo distance tăng dần)\n",
        "    # results.sort(key=lambda t: t[1], reverse=True) # Thường không cần vì Annoy đã sắp xếp theo distance\n",
        "\n",
        "    print(f\"Top {len(results)} relevant documents found:\")\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrVnaSk5sbLJ",
        "outputId": "05751898-4c36-41bd-8b0b-edf21cf96c9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 4 relevant documents found:\n",
            "- Similarity: 0.3570 | Document: With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.\n",
            "- Similarity: 0.2153 | Document: He points out that public transport is very good in Mumbai and New Delhi, where there is a good network of suburban and metro rail systems.\n",
            "- Similarity: 0.1817 | Document: But the man behind the wickets at the other end was watching just as keenly. With an affirmative nod from Dhoni, India captain Rohit Sharma promptly asked for a review. Sure enough, the ball would have clipped the top of middle and leg.\n",
            "- Similarity: 0.1237 | Document: Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\n"
          ]
        }
      ],
      "source": [
        "my_query = \"cabinet\"\n",
        "top_docs = ranked_documents_annoy(my_query, num_results=5)\n",
        "for doc, sim in top_docs:\n",
        "    print(f\"- Similarity: {sim:.4f} | Document: {doc}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
